{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "def file2matrix(dirname):\n",
    "    datamatrix=[]\n",
    "    label=[]\n",
    "    for root, dirs, files in os.walk('/home/zijun/digits/%s'% dirname):\n",
    "        for filename in files:\n",
    "            data_label=int(filename[0])\n",
    "            str_line=''\n",
    "            int_line=[]\n",
    "            with open('/home/zijun/digits/%s/%s' % (dirname,filename),'r') as fr:\n",
    "                data=fr.readlines()\n",
    "            for i in range(len(data)):\n",
    "                data[i]=data[i].rstrip('\\n')\n",
    "                str_line+=data[i]\n",
    "            for i in range(len(str_line)):\n",
    "                int_line.append(int(str_line[i]))  \n",
    "            datamatrix.append(int_line)\n",
    "            label.append(data_label)\n",
    "    return datamatrix,label\n",
    "\n",
    "def getEuclidDist(x1,x2):\n",
    "    dist=0\n",
    "    for i in range(len(x1)):\n",
    "        dist+=(x1[i]-x2[i])**2\n",
    "    return math.sqrt(dist)\n",
    "\n",
    "def getManDist(x1,x2):\n",
    "    dist=0\n",
    "    for i in range(len(x1)):\n",
    "        dist+=abs(x1[i]-x2[i])\n",
    "    return dist\n",
    "\n",
    "def getKNeighbors(k,datamatrix,label,new_data):\n",
    "    dist=[]\n",
    "    for i in range(len(datamatrix)):\n",
    "        dist.append((getEuclidDist(datamatrix[i],new_data),i,label[i]))\n",
    "    neighbors=sorted(dist)[:k]\n",
    "    return neighbors\n",
    "\n",
    "def makePredict(neighbors):\n",
    "    predict_dict={}\n",
    "    for i in neighbors:\n",
    "        if i[2] not in predict_dict:\n",
    "            predict_dict[i[2]]=1\n",
    "        else:\n",
    "            predict_dict[i[2]]+=1\n",
    "    return sorted(predict_dict.items(),key=lambda x:x[1],reverse=True)[0][0]\n",
    "\n",
    "def makePredict_weighted(neighbors):\n",
    "    predict_dict={}\n",
    "    for i in range(len(neighbors)):\n",
    "        if i==0:\n",
    "            weight=1\n",
    "        else:\n",
    "            try:\n",
    "                weight=(neighbors[-1][0]-neighbors[i][0])/(neighbors[-1][0]-neighbors[0][0])\n",
    "            except ZeroDivisionError:\n",
    "                weight=1\n",
    "        if neighbors[i][2] not in predict_dict:\n",
    "            predict_dict[neighbors[i][2]]=weight\n",
    "        else:\n",
    "            predict_dict[neighbors[i][2]]+=weight\n",
    "    return sorted(predict_dict.items(),key=lambda x:x[1],reverse=True)[0][0]\n",
    "\n",
    "def calAccuracy(predict_vec,label):\n",
    "    right_num=0\n",
    "    for i in range(len(predict_vec)):\n",
    "        if predict_vec[i]==label[i]:\n",
    "            right_num+=1\n",
    "    return right_num/len(predict_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9894291754756871\n",
      "time:416.852417\n"
     ]
    }
   ],
   "source": [
    "from time import clock\n",
    "if  __name__=='__main__':\n",
    "    train_data,train_label=file2matrix('trainingDigits')\n",
    "    test_data,test_label=file2matrix('testDigits')\n",
    "    predict_vec=[]\n",
    "    t0=clock()\n",
    "    for i in range(len(test_data)):\n",
    "        neighbors=getKNeighbors(3,train_data,train_label,test_data[i])\n",
    "        predict_vec.append(makePredict(neighbors))\n",
    "    acc=calAccuracy(predict_vec,test_label)\n",
    "    t1=clock()\n",
    "    print('accuracy:%s' % acc)\n",
    "    print('time:%s' % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9904862579281184\n",
      "time:411.57609599999995\n"
     ]
    }
   ],
   "source": [
    "from time import clock\n",
    "if  __name__=='__main__':\n",
    "    train_data,train_label=file2matrix('trainingDigits')\n",
    "    test_data,test_label=file2matrix('testDigits')\n",
    "    predict_vec=[]\n",
    "    t0=clock()\n",
    "    for i in range(len(test_data)):\n",
    "        neighbors=getKNeighbors(5,train_data,train_label,test_data[i])\n",
    "        predict_vec.append(makePredict_weighted(neighbors))\n",
    "    acc=calAccuracy(predict_vec,test_label)\n",
    "    t1=clock()\n",
    "    print('accuracy:%s' % acc)\n",
    "    print('time:%s' % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "class kdNode:\n",
    "    def __init__(self,data,left,right,split):\n",
    "        self.data=data\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.split=split\n",
    "    \n",
    "class kdTree:\n",
    "    def __init__(self,data_set):#data_set的格式是[(i,data[i]) for i in range(len(data))]\n",
    "        def createNode(data_set):\n",
    "            if len(data_set)==0:#数据集长度为0时终止\n",
    "                return None\n",
    "            else:\n",
    "                dim=[]\n",
    "                for i in range(len(data_set[0][1])):#求出数据矩阵的所有列向量\n",
    "                    dim.append([data_set[j][1][i] for j in range(len(data_set))])\n",
    "                variance=list(map(getVariance,dim))#求出所有列的方差\n",
    "                split=variance.index(max(variance))#选择方差最大的维度为切分维度   \n",
    "                data_set.sort(key=lambda x:x[1][split])#根据切分维度对数据排序\n",
    "                split_data=data_set[len(data_set)//2]\n",
    "                #把排序后数据集分成两半，分别用来建立当前结点的左右孩子，如此递归地建立kd树\n",
    "                root=kdNode(split_data,createNode(data_set[:len(data_set)//2]),createNode(data_set[len(data_set)//2+1:]),split)\n",
    "                return root\n",
    "                \n",
    "        def getVariance(l):\n",
    "            sum_1=reduce((lambda x,y:x+y),l)\n",
    "            mean=sum_1/len(l)\n",
    "            sum_2=reduce((lambda x,y:x+y),list(map((lambda x:x**2),l)))\n",
    "            return (sum_2/len(l)-mean**2)\n",
    "        \n",
    "        self.root=createNode(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import *\n",
    "def search_knn(tree,point,k):\n",
    "    result=[]\n",
    "    def search_node(node,point,result,k):\n",
    "        if not node:#结点为空时终止\n",
    "            return\n",
    "        else:\n",
    "            node_dist=getEuclidDist(node.data[1],point)#求当前结点保存的数据与目的数据的距离\n",
    "            item=(-node_dist,node.data)#把距离的相反数和数据打包成元组\n",
    "            #当优先队列元素已经达到k时，只有当前结点的距离小于优先队列中的最大距离时才把当前结点加入优先队列，替换队列中距离最大的结点\n",
    "            if len(result)>=k:\n",
    "                if -node_dist>result[0][0]:\n",
    "                    heapreplace(result, item)\n",
    "            else:\n",
    "                heappush(result, item)#队列元素数量小于k时直接把当前结点加入\n",
    "            #递归搜索目的数据所在的孩子结点，更新优先队列\n",
    "            if node.data[1][node.split]>=point[node.split]:\n",
    "                search_node(node.left,point,result,k)\n",
    "                next_node=node.right\n",
    "            else:\n",
    "                search_node(node.right,point,result,k)\n",
    "                next_node=node.left\n",
    "            #如果优先队列中的最大距离小于目的结点到分割超平面的距离，就不需要搜索另一个孩子结点，否则搜索另一个孩子节点\n",
    "            if -abs(node.data[1][node.split]-point[node.split])>result[0][0] or len(result)<k:\n",
    "                search_node(next_node,point,result,k)\n",
    "    \n",
    "    search_node(tree.root,point,result,k)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9809725158562368\n",
      "time:208.44325000000003\n"
     ]
    }
   ],
   "source": [
    "from time import clock\n",
    "if  __name__=='__main__':\n",
    "    train_data,train_label=file2matrix('trainingDigits')\n",
    "    test_data,test_label=file2matrix('testDigits')\n",
    "    dataset=[(i,test_data[i]) for i in range(len(test_data))]\n",
    "    t0=clock()\n",
    "    kd = kdTree(dataset)\n",
    "    predict_vec=[]\n",
    "    for i in range(len(test_data)):\n",
    "        result=search_knn(kd,test_data[i],5)\n",
    "        neighbors=[(-j[0],j[1][0],test_label[j[1][0]]) for j in result]\n",
    "        predict_vec.append(makePredict(neighbors))\n",
    "    acc=calAccuracy(predict_vec,test_label)\n",
    "    t1=clock()\n",
    "    print('accuracy:%s' % acc)\n",
    "    print('time:%s' % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import *\n",
    "def search_knn_norecur(tree,point,k):\n",
    "    result=[]\n",
    "    def search_node(node,point,result,k):\n",
    "        node_stack=[]\n",
    "        temp_node=node\n",
    "        #从根结点开始找到目的数据所在的叶子结点，中间所有路过的结点都压入node_stack\n",
    "        while temp_node:\n",
    "            node_stack.append(temp_node)\n",
    "            if temp_node.data[1][temp_node.split]>=point[temp_node.split]:\n",
    "                temp_node=temp_node.left\n",
    "            else:\n",
    "                temp_node=temp_node.right\n",
    "        #分别处理node_stack中的每个结点，对于每个结点求距离并更新优先队列\n",
    "        while len(node_stack)>0:\n",
    "            node=node_stack.pop()\n",
    "            node_dist=getEuclidDist(node.data[1],point)\n",
    "            item=(-node_dist,node.data)\n",
    "            if len(result)>=k:\n",
    "                if -node_dist>result[0][0]:\n",
    "                    heapreplace(result, item)\n",
    "            else:\n",
    "                heappush(result, item)\n",
    "            #如果优先队列中的最大距离大于目的结点到分割超平面的距离，把未搜索的另一个子结点压栈\n",
    "            if -abs(node.data[1][node.split]-point[node.split])>result[0][0] or len(result)<k:\n",
    "                if node.data[1][node.split]>=point[node.split]:\n",
    "                    if node.right:\n",
    "                        node=node.right\n",
    "                    else:\n",
    "                        node=None\n",
    "                else:\n",
    "                    if node.left:\n",
    "                        node=node.left\n",
    "                    else:\n",
    "                        node=None\n",
    "            #如果压栈的另一个子结点不是叶子结点，则递归地查找到目的数据所在的叶子结点，路过的所有节点均压栈\n",
    "            if node:\n",
    "                while node.left or node.right:\n",
    "                    node_stack.append(node)\n",
    "                    if node.data[1][node.split]>=point[node.split]:\n",
    "                        if not node.left:\n",
    "                            break\n",
    "                        else:\n",
    "                            node=node.left\n",
    "                    else:\n",
    "                        if not node.right:\n",
    "                            break\n",
    "                        else:\n",
    "                            node=node.right\n",
    "                if node.left==None and node.right==None:\n",
    "                    node_stack.append(node)\n",
    "    search_node(tree.root,point,result,k)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9809725158562368\n",
      "time:205.4363760000001\n"
     ]
    }
   ],
   "source": [
    "from time import clock\n",
    "if  __name__=='__main__':\n",
    "    train_data,train_label=file2matrix('trainingDigits')\n",
    "    test_data,test_label=file2matrix('testDigits')\n",
    "    dataset=[(i,test_data[i]) for i in range(len(test_data))]\n",
    "    t0=clock()\n",
    "    kd = kdTree(dataset)\n",
    "    predict_vec=[]\n",
    "    for i in range(len(test_data)):\n",
    "        result=search_knn_norecur(kd,test_data[i],5)\n",
    "        neighbors=[(-j[0],j[1][0],test_label[j[1][0]]) for j in result]\n",
    "        predict_vec.append(makePredict(neighbors))\n",
    "    acc=calAccuracy(predict_vec,test_label)\n",
    "    t1=clock()\n",
    "    print(acc)\n",
    "    print('time:%s' % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
